# 1 Human Agency and Oversight (HUM)

AI systems should support human autonomy and decision-making, as prescribed by the principle of respect for human autonomy. This requires that AI systems should both act as enablers to a democratic, flourishing and equitable society by supporting the user’s agency and foster fundamental rights and allow for human oversight.

## 1.1 Fundamental rights

Like many technologies, AI systems can equally enable and hamper fundamental rights. They can benefit people for instance by helping them track their personal data, or by increasing the accessibility of education, hence supporting their right to education. However, given the reach and capacity of AI systems, they can also negatively affect fundamental rights. In situations where such risks exist, a fundamental rights impact assessment should be undertaken. This should be done prior to the system’s development and include an evaluation of whether those risks can be reduced or justified as necessary in a democratic society in order to respect the rights and freedoms of others. Moreover, mechanisms should be put into place to receive external feedback regarding AI systems that potentially infringe on fundamental rights.

| **Question**        | **Considerations**                     |
|----------------------|---------------------------------------|
| Should a fundamental rights impact assessment be performed? | Could your models potentially affect fundamental rights: respect for human dignity, freedom, democracy, equality, rule of law, or respect for human rights?|
| If you have performed a fundamental rights impact assessment, what are your results?| Provide specifically justification what type of assessment you chose, why, and how you assess the validity of the results.|

## 1.2 Human Agency

Users should be able to make informed autonomous decisions regarding AI systems. They should be given the knowledge and tools to comprehend and interact with AI systems to a satisfactory degree and, where possible, be enabled to reasonably self-assess or challenge the system. AI systems should support individuals in making better, more informed choices in accordance with their goals. AI systems can sometimes be deployed to shape and influence human behaviour through mechanisms that may be difficult to detect, since they may harness sub-conscious processes, including various forms of unfair manipulation, deception, herding and conditioning, all of which may threaten individual autonomy. The overall principle of user autonomy must be central to the system’s functionality. Key to this is the right not to be subject to a decision based solely on automated processing when this produces legal effects on users or similarly significantly affects them.

| **Question**        | **Considerations**                     |
|----------------------|---------------------------------------|
| Are appropriate training protocols devised and observed for all users of the toolbox?| Human agency requires adequate knowledge about the capabilities of a system. This ensures that given information is not blindly followed, to avoid automation bias. A training protocol or systematized evaluation of training needs must be made before interacting with a system.|
| What information were users of the toolbox provided prior to interacting with the toolbox?| Human agency requires adequate information on the basis of which decisions can be taken. This requires a deep and sufficient understanding of the toolbox capabilities.|
| Which measures did you implement to avoid that end-user over-rely on the toolbox methods and critically assess their interaction with the toolbox methods?| Consciously and systematically reviewing how to interact with the toolbox helps maintaining human agency in the development process.|

## 1.3 Human Oversight

Human oversight helps ensuring that an AI system does not undermine human autonomy or causes other adverse effects. Oversight may be achieved through governance mechanisms such as a human-in-the-loop (HITL), human-on-the-loop (HOTL), or human-in-command (HIC) approach. 
HITL refers to the capability for human intervention in every decision cycle of the system, which in many cases is neither possible nor desirable. 
HOTL refers to the capability for human intervention during the design cycle of the system and monitoring the system’s operation. 
HIC refers to the capability to oversee the overall activity of the AI system (including its broader economic, societal, legal and ethical impact) and the ability to decide when and how to use the system in any particular situation. This can include the decision not to use an AI system in a particular situation, to establish levels of human discretion during the use of the system, or to ensure the ability to override a decision made by a system. 
Moreover, it must be ensured that public enforcers have the ability to exercise oversight in line with their mandate. Oversight mechanisms can be required in varying degrees to support other safety and control measures, depending on the AI system’s application area and potential risk. All other things being equal, the less oversight a human can exercise over an AI system, the more extensive testing and stricter governance is required.

| **Question**        | **Considerations**                     |
|----------------------|---------------------------------------|
| Describe what type of human oversight was integrated into the decision-making processes when using the toolbox (HITL, HOTL, or HIC)?| Human agency requires adequate knowledge about the capabilities of a system. This ensures that given information is not blindly followed, to avoid automation bias. A training protocol or systematized evaluation of training needs must be made before interacting with a systeConsider the above presented definitions of these concepts.|
| Describe measures taken to make  interaction with the toolbox and the development of models based on the toolbox auditable.| Human oversight requires that other can audit your decisions and oversight mechanisms. While public enforcers will only operate in regulated environments, it it is still advisable to have your work audited, and to make information publicly as much available as possible.|
| Have the users of the toolbox been given specific training how to exercise oversight?| Even if oversight measures have been taken, the users need to be trained in applying them.|
