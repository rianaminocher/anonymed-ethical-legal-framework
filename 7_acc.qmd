# 7 Accountability (ACC)

The requirement of accountability complements the above requirements, and is closely linked to the principle of fairness. It necessitates that mechanisms be put in place to ensure responsibility and accountability for AI systems and their outcomes, both before and after their development, deployment and use.

## 7.1	Auditability

Auditability entails the enablement of the assessment of algorithms, data and design processes. This does not necessarily imply that information about business models and intellectual property related to the AI system must always be openly available. Evaluation by internal and external auditors, and the availability of such evaluation reports, can contribute to the trustworthiness of the technology. In applications affecting fundamental rights, including safety-critical applications, AI systems should be able to be independently audited.

| **Question**        | **Considerations**                     |
|----------------------|---------------------------------------|
| Describe the process for documenting the choices and their related justification during development when faced with dilemmas and trade-offs?| You may want to include  descriptions of topics such as but not limited to: The context, alternatives, choice made, justification, decision-makers, who was consulted, and the date. You may want to establish mechanisms such as traceability of the development process, of the sourcing of training data and the logging of AI model processes, outcomes, and positive or negative impact)|

## 7.2	Minimisation and reporting of negative impacts

Both the ability to report on actions or decisions that contribute to a certain system outcome, and to respond to the consequences of such an outcome, must be ensured. Identifying, assessing, reporting and minimising the potential negative impacts of AI systems is especially crucial for those (in)directly affected. Due protection must be available for whistle-blowers, NGOs, trade unions or other entities when reporting legitimate concerns about an AI-based system. The use of impact assessments (e.g. red teaming or forms of Algorithmic Impact Assessment) both prior to and during the development, deployment and use of AI systems can be helpful to minimise negative impact. These assessments must be proportionate to the risk that the AI systems pose.

| **Question**        | **Considerations**                     |
|----------------------|---------------------------------------|
| Describe the process that has been set up for reporting of negative impacts? Has an assessment been made on what kind of issues should be monitored for and how the reporting format should look like to accommodate such issues?| You may want to consider an SOP for reporting negative impacts and protections for whistle-blowers, or broadly anonymous feedback.|
| Describe your results of the Algorithmic Impact Assessment (AIA).| You may want to scale your AIA with the size of your AI project. When using HE, you should consider latency and throughput considerable challenges [18, p. 2]|

## 7.3	Trade-offs

When implementing the above requirements, tensions may arise between them, which may lead to inevitable trade-offs. Such trade-offs should be addressed in a rational and methodological manner within the state of the art. This entails that relevant interests and values implicated by the AI system should be identified and that, if conflict arises, trade-offs should be explicitly acknowledged and evaluated in terms of their risk to ethical principles, including fundamental rights. In situations in which no ethically acceptable trade-offs can be identified, the development, deployment and use of the AI system should not proceed in that form. Any decision about which trade-off to make should be reasoned and properly documented. The decision-maker must be accountable for the manner in which the appropriate trade-off is being made, and should continually review the appropriateness of the resulting decision to ensure that necessary changes can be made to the system where needed.

| **Question**        | **Considerations**                     |
|----------------------|---------------------------------------|
| Describe your approach how to identify, mitigate, and solve ethical tensions between the ethical principles of this framework.| A good starting point is the report of Whittlestone et al from the Nuffield foundation. [19]|

## 7.4	Redress

When unjust adverse impact occurs, accessible mechanisms should be foreseen that ensure adequate redress. Knowing that redress is possible when things go wrong is key to ensure trust. Particular attention should be paid to vulnerable persons or groups.

| **Question**        | **Considerations**                     |
|----------------------|---------------------------------------|
| Describe your measures and or processes for redress.| You may want to consider for example how it will be remediated if it is later revealed that sensitive information can be inferred from the models or datasets shared.|
